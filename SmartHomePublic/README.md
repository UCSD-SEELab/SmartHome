# SEELab SmartHome Repository

Welcome to the SEELab SmartHome repository!

## Repository Structure

The repository is organized into the following sub-directories:

```
  /code
    /analysis - Code to run comparison of hierarchy aware and monolithic inference
    /cleaning - Code to process raw data files and extract features
    /lib      - TensorFlow implementation of hierarchical neural network
    /utils    - Utility Python code used for cleaning and analysis 
    
  /data - Contains raw data files extracted from SmartHome deployment
  
  /output - Contains persistent output produced by code in `analysis`. 
            TensorFlow saved model files are written here.
```

## Quick and Easy Feature Extraction

To generate a dataset for analysis perform the following steps:

```
# (1) Clone this repository
git clone <URL>/SmartHomePublic.git
cd SmartHomePublic

# (2) Install necessary python packages
pip install -r requirements.txt

# (3) Run code to parse raw data and extract features
# WARNING: THIS WILL DELETE ALL EXISTING FILES IN /temp AND /output
cd SmartHomePublic/code/cleaning
python run.py
```

The output of this process will be an HDF5 file containing two Pandas data frames which can be used in analysis algorithms. The label of each observation is contained in the column `label`. For detailed examples of how to use these files inspect `/code/analysis/mlp.py`. For detailed documentation on Pandas see: [Pandas Tutorials](https://pandas.pydata.org/pandas-docs/stable/tutorials.html) A simple example is given below:

```
import pandas as pd
processed_data = pd.read_hdf("../../temp/data_processed.h5", "subject1")
processed_data.describe()  # Print a summary of the dataset
```

In the following three sections we document in greater detail the steps performed to extract raw data and perform analysis.

## Data Description

**Note: we provide data parsing scripts. This section merely provides documentation for completeness**. We provide output from three rounds of data collection performed on three different days in the same location. Raw data files are contained in the `/data` directory. The files are named: `MQTT_Messages_subject<number>_<date>.txt`. Each row in a file corresponds to one reading from one sensor. An example row is described below:

`Topic:#pir/angular_locations#Message:#{"posy": 19.0, "angle1": 45.0, "posx": 6.0, "angle2": 45.0}`

`Topic:#` indcates the sensor corresponding to this data item. In the example above, the sensor is the `pir/angular_locations` sensor. `Message:#` is the JSON object containing the data generated by the sensor. There are two data stream which do not conform to this format:

1) **Smart Watch** The data fields produced by the smart watch a `;` delimited:

`Topic:#watch#Message:#step;9047.0;hrm;137.0;acc;-6.23;-0.531;6.601;gyro;-0.947;0.29;0.402;ts;11/16 13:37:45:879`

2) **Smart Things** The smart things data streams return only a single value:

`Topic:#smartthings/Fridge/temperature#Message:#70`

In this example the `smartthings/Fridge/temperature` topic produces the message `70`

## Data Parsing

Code to parse the raw data files is contained in `/code/cleaning`. Data parsing is performed by two code files:

1. `read_data.py`: This file reads the raw `.txt` data files and converts each sensor data stream into a Python data structure. The output is a dictionary whose keys are the names of data streams (topics) and whose values are lists containing the corresponding raw data. Little to no data processing is performed in this stage. The timestamp of sensor messages are aligned with the timestamp of the smart-watch which samples at the highest rate.
2. `preclean.py`: This file takes the output of (1) and converts each data stream into a Pandas data frame. Data frames are saved into an HDF5 file (requires `pytables`) organized by topic name.

## Feature Extraction

Code to extract features from data is contained in `/code/cleaning/build.py`. **Before running this program you must run preclean.py which generates input data**. Feature extraction methodology is described in detail below. Before analysis, the features of both train and test datasets are rescaled to the mean and variance of the training data (thus, values represent deviations from this mean).

1. **Time Series Alignment** Each sensor gathers data at a different sampling rate. The sensor with the highest sampling rate is the watch which generates (approximately) 10 samples per second. To align the time-series of the other data streams we assign we assign each data item received the timestamp of the most recently received watch message. To produce an analysis dataset we then join the data streams by timestamp and project forward to fill missing values. An example is given below:

```
WATCH_DATA:                METASENSE_DATA               WATCH_DATA LEFT JOIN METASENSE_DATA ON timestamp
timestamp    heartrate     timestamp    temperature            timestamp heartrate temperature
   0.0          68            0.1           28                    0.0       68         NULL
   0.1          70            0.3           29                    0.1       70          28
   0.2          75                                                0.2       75          28
   0.3          72                                                0.3       72          29
   0.4          69                                                0.4       69          29
   
Example in Pandas:

watch_data.join(metasense_data, how="left").fillna(method="ffill").dropna()
```
2. **Smart Watch** - The smart watch samples every 0.1 seconds. We extract features from the smart-watch using a rolling window of 30 observations (about 3 seconds) with a step of 1 observation. The watch generates the following features XYZ acceleration and gyro (roll, pitch, yaw) along with heart rate. We determined the heart rate monitor to be innaccurate and so exclude this feature. For the remaining features we extract the following data over the rolling window: mean, variance, pairwise correlation, energy (normalized sum of squared FFT coefficients). Although not used in our analysis algorithm we additionally provide code to decompose each signal into a high and low precision signal using a wavelet decomposition from which features can be extracted.
3. **Metasense** - The metasense samples once every 5 seconds. The metasense generates data on `CO2` concentration, tempaerature, pressure, humidity and concentration of particulate matter of various sizes. We extract a rolling mean and variance of each feature of the past 3 observations (about 15 seconds). We note that the pressure sensor was quite noisy and we exclude it from our analysis.
4. **Smart Plugs** - The smart plugs sample once every 5 seconds. The smart plug generates a measure of current drawn and voltage. We use only the current drawn by the plug. As in the case of the metasense we compute a mean and variance over the past 3 observations.
5. **Pressure Mat** - The pressure mat returns a `16x32` array of integers indicating the observed pressure on each of the corresponding `512` sensors. We aggregate each array into a sum and compute a rolling mean and variance over the past three observations. This serves as an "indiactor" feature for if someone is standing on the mat and additionally provides the option to descriminate the identity of the test subject from their approximate weight.
6. **Open Close Sensors** - The contact sensors indicate if a door is open or closed. We process these features into a set of three binary features indicating if the corresponding door has been opened in the previous 1, 5 or 10 minutes. A value is sent only when there is a change in state detected (i.e. the door is opened or closed)
7. **Bluetooth Locator Beacons** - There are four bluetooth locator beacons named `rssi<1-4>`. Beacons 1 and 2 are located in the kitchen, beacon 3 is located in the dining room, and beacons 4 and 5 are located in the living room. Each beacon returns a value between -100 and -1 with larger values indicating closer proximity. A value of `0` indicates no data. We process these into a three boolean feature indicating if the test subject was in the kitchen, living room or dining room. To compute these values we replace 0's with -9999 and then compute an argmax over the vector of returned values.

## Model training

Code to run the models is contained in `/code/analysis/`. The quick way to run the model training is using "python run.py". This script will train the hierarchical neural networks and export the weights of trained models for each device. 
The code in mlp.py is the code for actual training. The model can be trained in two modes: `HierarchyAwareMLP` or `FullyConnectedMLP`. By specifying the classifer type `clf`, the model can be trained in different modes. In the `HierarchyAwareMLP`, each device has a small network for local computation. The output of the local compuataion is feed into the next level in the hierarchy for further preprocessing. The cloud aggregates all the outputs in the lower level and make the final predictons. The code for building the hierarchy is in the function `get_output()`, it can be modified in various ways to consider different hierarchical structures. In the `FullyConnectedMLP`, all the local devices send the data directly to the cloud and the computation only happens in the cloud. 

After finishing training, the function `freeze_graph()` stores the trained model for each device. The stored models can be recovered using export_mlp_weights.py. In export_mlp_weights.py, the function `load_frozen_graph()` loads the trained models back for each device and should be put in the device which needs to carry local computation. The function `get_actual_weights()` exports the weights of each trained model into text files. In this way, we can convert the trained models into other languages such as C/C++ which is necessary for devices which do not have enough computation power. The function `hierarchical_inference()` gives an example on how to load the trained models back and does inference in the hierarchy. The basic idea is that each device sends the computed output to the next higher level devive. The higher level device concats all the output from the lower devices and use that as the input of its own model. For deployment, the code for concating the outputs of lower local devices should be placed in any device which needs to aggregate the lower level outputs. 